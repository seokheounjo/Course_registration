"""
ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ - GPU ì§€ì› ë° ì§„í–‰ ìƒí™© í‘œì‹œ ê°œì„ 
"""

import os
import json
import logging
import torch
import platform
from enum import Enum
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, field
from tqdm import tqdm
import psutil

class OCREngine(Enum):
    """OCR ì—”ì§„ ì¢…ë¥˜"""
    PADDLEOCR = "paddleocr"
    EASYOCR = "easyocr"
    TESSERACT = "tesseract"
    TROCR = "trocr"

class OutputFormat(Enum):
    """ì¶œë ¥ í˜•ì‹"""
    JSON = "json"
    CSV = "csv"
    EXCEL = "excel"
    HTML = "html"

class LayoutModel(Enum):
    """ë ˆì´ì•„ì›ƒ ë¶„ì„ ëª¨ë¸"""
    LAYOUTLMV3 = "layoutlmv3"
    DETECTRON2 = "detectron2"
    RULE_BASED = "rule_based"

@dataclass
class Config:
    """ì „ì²´ ì„¤ì • í´ë˜ìŠ¤"""
    
    # ê²½ë¡œ ì„¤ì •
    project_root: Path = field(default_factory=lambda: Path(__file__).parent.parent)
    output_dir: Path = field(default_factory=lambda: Path("output"))
    cache_dir: Path = field(default_factory=lambda: Path("cache"))
    data_dir: Path = field(default_factory=lambda: Path("data"))
    
    # OCR ì„¤ì •
    ocr_engine: OCREngine = OCREngine.EASYOCR
    ocr_languages: List[str] = field(default_factory=lambda: ["ko", "en"])
    
    # ë ˆì´ì•„ì›ƒ ë¶„ì„ ì„¤ì •
    layout_model: LayoutModel = LayoutModel.RULE_BASED
    
    # ì²˜ë¦¬ ì„¤ì •
    dpi: int = 200
    batch_size: int = 5
    max_workers: int = 1
    device: str = "auto"  # "auto", "cuda", "cpu"
    gpu_memory_fraction: float = 0.8  # GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„ìœ¨
    
    # ê¸°ëŠ¥ ì„¤ì •
    extract_tables: bool = True
    extract_formulas: bool = True
    extract_financial_terms: bool = True
    detect_korean_formulas: bool = True
    korean_nlp_enabled: bool = True
    
    # ì¶œë ¥ ì„¤ì •
    output_formats: List[OutputFormat] = field(default_factory=lambda: [OutputFormat.CSV, OutputFormat.JSON])
    save_intermediate: bool = False
    compress_output: bool = False
    
    # ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_file: Optional[Path] = None
    show_progress: bool = True  # ì§„í–‰ ìƒí™© í‘œì‹œ
    
    # ìºì‹œ ì„¤ì •
    use_cache: bool = True
    cache_expiry_days: int = 7
    
    # ê¸ˆìœµ ìš©ì–´ ë° ìˆ˜ì‹ íŒ¨í„´
    _financial_terms: Optional[Dict[str, Any]] = None
    _korean_formula_patterns: Optional[Dict[str, Any]] = None
    
    # GPU ì •ë³´
    _gpu_info: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        self.output_dir = self.project_root / self.output_dir
        self.cache_dir = self.project_root / self.cache_dir
        self.data_dir = self.project_root / self.data_dir
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(exist_ok=True)
        self.cache_dir.mkdir(exist_ok=True)
        self.data_dir.mkdir(exist_ok=True)
        
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±
        (self.output_dir / "csv").mkdir(exist_ok=True)
        (self.output_dir / "individual").mkdir(exist_ok=True)
        (self.output_dir / "logs").mkdir(exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼ ì„¤ì •
        if self.log_file is None:
            self.log_file = self.output_dir / "logs" / "analysis.log"
        
        # GPU ì„¤ì •
        self._setup_gpu()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        self._print_system_info()
    
    def _setup_gpu(self):
        """GPU ì„¤ì • ë° í™•ì¸"""
        if self.device == "auto":
            if torch.cuda.is_available():
                self.device = "cuda"
                # GPU ë©”ëª¨ë¦¬ ì„¤ì •
                torch.cuda.set_per_process_memory_fraction(self.gpu_memory_fraction)
            else:
                self.device = "cpu"
        
        # GPU ì •ë³´ ìˆ˜ì§‘
        if self.device == "cuda" and torch.cuda.is_available():
            self._gpu_info = {
                "available": True,
                "device_count": torch.cuda.device_count(),
                "device_name": torch.cuda.get_device_name(0),
                "memory_total": torch.cuda.get_device_properties(0).total_memory / (1024**3),  # GB
                "memory_allocated": torch.cuda.memory_allocated(0) / (1024**3),  # GB
                "memory_reserved": torch.cuda.memory_reserved(0) / (1024**3),  # GB
            }
        else:
            self._gpu_info = {"available": False}
    
    def _print_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ ì •ë³´")
        print("="*60)
        
        # OS ì •ë³´
        print(f"ìš´ì˜ì²´ì œ: {platform.system()} {platform.release()}")
        print(f"Python ë²„ì „: {platform.python_version()}")
        
        # CPU ì •ë³´
        print(f"CPU ì½”ì–´: {psutil.cpu_count(logical=False)}ê°œ (ë…¼ë¦¬: {psutil.cpu_count(logical=True)}ê°œ)")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory = psutil.virtual_memory()
        print(f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {memory.total / (1024**3):.1f}GB (ì‚¬ìš© ê°€ëŠ¥: {memory.available / (1024**3):.1f}GB)")
        
        # GPU ì •ë³´
        if self._gpu_info and self._gpu_info["available"]:
            print(f"\nğŸ® GPU ì •ë³´")
            print(f"GPU ì¥ì¹˜: {self._gpu_info['device_name']}")
            print(f"GPU ë©”ëª¨ë¦¬: {self._gpu_info['memory_total']:.1f}GB")
            print(f"ì‚¬ìš© ì„¤ì •: {self.device.upper()} (ë©”ëª¨ë¦¬ {self.gpu_memory_fraction*100:.0f}% í• ë‹¹)")
            print("âœ… GPU ê°€ì†ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"\nâš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            print("ğŸ’¡ íŒ: CUDA ì§€ì› GPUì™€ PyTorch CUDAë¥¼ ì„¤ì¹˜í•˜ë©´ ì²˜ë¦¬ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")
        
        print("="*60 + "\n")
    
    @property
    def financial_terms(self) -> Dict[str, Any]:
        """ê¸ˆìœµ ìš©ì–´ ì‚¬ì „ ë¡œë“œ"""
        if self._financial_terms is None:
            terms_file = self.data_dir / "financial_terms.json"
            if terms_file.exists():
                with open(terms_file, 'r', encoding='utf-8') as f:
                    self._financial_terms = json.load(f)
            else:
                self._financial_terms = {}
        return self._financial_terms
    
    @property
    def korean_formula_patterns(self) -> Dict[str, Any]:
        """í•œê¸€ ìˆ˜ì‹ íŒ¨í„´ ë¡œë“œ"""
        if self._korean_formula_patterns is None:
            patterns_file = self.data_dir / "korean_formula_patterns.json"
            if patterns_file.exists():
                with open(patterns_file, 'r', encoding='utf-8') as f:
                    self._korean_formula_patterns = json.load(f)
            else:
                self._korean_formula_patterns = {}
        return self._korean_formula_patterns
    
    def get_output_path(self, document_id: str, output_type: str, filename: str) -> Path:
        """ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        if output_type == "csv":
            return self.output_dir / "csv" / f"{document_id}_{filename}"
        elif output_type == "individual":
            return self.output_dir / "individual" / document_id / filename
        else:
            return self.output_dir / filename
    
    def setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        from utils.logging_utils import LoggingUtils
        
        # ë¡œê·¸ íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸
        if self.log_file:
            self.log_file.parent.mkdir(parents=True, exist_ok=True)
        
        logger = LoggingUtils.setup_logger(
            name="financial_pdf_analyzer",
            log_file=self.log_file,
            level=self.log_level
        )
        
        return logger
    
    def get_gpu_memory_info(self) -> Dict[str, float]:
        """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ"""
        if self.device == "cuda" and torch.cuda.is_available():
            return {
                "allocated": torch.cuda.memory_allocated(0) / (1024**3),
                "reserved": torch.cuda.memory_reserved(0) / (1024**3),
                "free": (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / (1024**3)
            }
        return {"allocated": 0, "reserved": 0, "free": 0}
    
    def create_progress_bar(self, total: int, desc: str, unit: str = "pages") -> tqdm:
        """ì§„í–‰ ìƒí™© í‘œì‹œ ë°” ìƒì„±"""
        if self.show_progress:
            return tqdm(
                total=total,
                desc=desc,
                unit=unit,
                ncols=100,
                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'
            )
        else:
            # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ìŒ
            class DummyProgress:
                def update(self, n=1): pass
                def set_postfix(self, **kwargs): pass
                def close(self): pass
            return DummyProgress()
    
    def to_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "project_root": str(self.project_root),
            "output_dir": str(self.output_dir),
            "cache_dir": str(self.cache_dir),
            "ocr_engine": self.ocr_engine.value,
            "ocr_languages": self.ocr_languages,
            "layout_model": self.layout_model.value,
            "dpi": self.dpi,
            "batch_size": self.batch_size,
            "max_workers": self.max_workers,
            "device": self.device,
            "gpu_memory_fraction": self.gpu_memory_fraction,
            "extract_tables": self.extract_tables,
            "extract_formulas": self.extract_formulas,
            "extract_financial_terms": self.extract_financial_terms,
            "output_formats": [fmt.value for fmt in self.output_formats],
            "log_level": self.log_level,
            "show_progress": self.show_progress,
            "gpu_info": self._gpu_info
        }
    
    def save(self, filepath: Path):
        """ì„¤ì • ì €ì¥"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
    
    @classmethod
    def load(cls, filepath: Path) -> 'Config':
        """ì„¤ì • ë¡œë“œ"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Enum ë³€í™˜
        if 'ocr_engine' in data:
            data['ocr_engine'] = OCREngine(data['ocr_engine'])
        if 'layout_model' in data:
            data['layout_model'] = LayoutModel(data['layout_model'])
        if 'output_formats' in data:
            data['output_formats'] = [OutputFormat(fmt) for fmt in data['output_formats']]
        
        # Path ë³€í™˜
        for key in ['project_root', 'output_dir', 'cache_dir', 'data_dir', 'log_file']:
            if key in data and data[key]:
                data[key] = Path(data[key])
        
        # GPU ì •ë³´ëŠ” ë¡œë“œí•˜ì§€ ì•ŠìŒ (ì¬ê²€ì‚¬ í•„ìš”)
        data.pop('gpu_info', None)
        
        return cls(**data)