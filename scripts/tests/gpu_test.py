# -*- coding: utf-8 -*-
#!/usr/bin/env python3
"""
GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™” í™•ì¸
"""

import sys
import time
import torch
import numpy as np
from pathlib import Path

def print_gpu_info():
    """GPU ì •ë³´ ì¶œë ¥"""
    print("\nğŸ® GPU ì •ë³´")
    print("="*60)
    
    if not torch.cuda.is_available():
        print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    device_count = torch.cuda.device_count()
    print(f"GPU ê°œìˆ˜: {device_count}ê°œ")
    
    for i in range(device_count):
        props = torch.cuda.get_device_properties(i)
        print(f"\nGPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"  â€¢ ì»´í“¨íŠ¸ ëŠ¥ë ¥: {props.major}.{props.minor}")
        print(f"  â€¢ ì „ì²´ ë©”ëª¨ë¦¬: {props.total_memory / (1024**3):.1f}GB")
        print(f"  â€¢ ë©€í‹°í”„ë¡œì„¸ì„œ: {props.multi_processor_count}ê°œ")
        print(f"  â€¢ CUDA ì½”ì–´: ~{props.multi_processor_count * 64}ê°œ (ì¶”ì •)")
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        allocated = torch.cuda.memory_allocated(i) / (1024**3)
        reserved = torch.cuda.memory_reserved(i) / (1024**3)
        print(f"  â€¢ í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.1f}GB")
        print(f"  â€¢ ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {reserved:.1f}GB")
        print(f"  â€¢ ì‚¬ìš© ê°€ëŠ¥: {(props.total_memory / (1024**3) - allocated):.1f}GB")
    
    print(f"\nCUDA ë²„ì „: {torch.version.cuda}")
    print(f"cuDNN ë²„ì „: {torch.backends.cudnn.version()}")
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    
    return True

def test_gpu_performance():
    """GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nâš¡ GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    device = torch.device('cuda')
    
    # í…ŒìŠ¤íŠ¸ í¬ê¸°ë“¤
    test_sizes = [
        (1000, 1000),
        (5000, 5000),
        (10000, 10000)
    ]
    
    for size in test_sizes:
        print(f"\ní–‰ë ¬ í¬ê¸°: {size[0]}x{size[1]}")
        
        # CPU í…ŒìŠ¤íŠ¸
        cpu_matrix1 = torch.randn(size)
        cpu_matrix2 = torch.randn(size)
        
        start = time.time()
        cpu_result = torch.matmul(cpu_matrix1, cpu_matrix2)
        cpu_time = time.time() - start
        
        # GPU í…ŒìŠ¤íŠ¸
        gpu_matrix1 = cpu_matrix1.to(device)
        gpu_matrix2 = cpu_matrix2.to(device)
        
        # ì›Œë°ì—…
        _ = torch.matmul(gpu_matrix1, gpu_matrix2)
        torch.cuda.synchronize()
        
        start = time.time()
        gpu_result = torch.matmul(gpu_matrix1, gpu_matrix2)
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        
        speedup = cpu_time / gpu_time
        
        print(f"  â€¢ CPU ì‹œê°„: {cpu_time:.4f}ì´ˆ")
        print(f"  â€¢ GPU ì‹œê°„: {gpu_time:.4f}ì´ˆ")
        print(f"  â€¢ ì†ë„ í–¥ìƒ: {speedup:.1f}ë°°")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del cpu_matrix1, cpu_matrix2, cpu_result
        del gpu_matrix1, gpu_matrix2, gpu_result
        torch.cuda.empty_cache()

def test_ocr_engines():
    """OCR ì—”ì§„ GPU ì§€ì› í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¤ OCR ì—”ì§„ GPU ì§€ì› í™•ì¸")
    print("="*60)
    
    # EasyOCR
    try:
        import easyocr
        print("\nâœ… EasyOCR ì„¤ì¹˜ë¨")
        print("   GPU ì§€ì›: ì˜ˆ")
    except ImportError:
        print("\nâŒ EasyOCR ë¯¸ì„¤ì¹˜")
        print("   ì„¤ì¹˜: pip install easyocr")
    
    # PaddleOCR
    try:
        import paddleocr
        print("\nâœ… PaddleOCR ì„¤ì¹˜ë¨")
        print("   GPU ì§€ì›: ì˜ˆ")
    except ImportError:
        print("\nâŒ PaddleOCR ë¯¸ì„¤ì¹˜")
        print("   ì„¤ì¹˜: pip install paddlepaddle paddleocr")
    
    # Tesseract
    try:
        import pytesseract
        print("\nâœ… Tesseract ì„¤ì¹˜ë¨")
        print("   GPU ì§€ì›: ì•„ë‹ˆì˜¤ (CPU ì „ìš©)")
    except ImportError:
        print("\nâŒ Tesseract ë¯¸ì„¤ì¹˜")
        print("   ì„¤ì¹˜: pip install pytesseract")
    
    # TrOCR
    try:
        import transformers
        print("\nâœ… Transformers ì„¤ì¹˜ë¨ (TrOCR)")
        print("   GPU ì§€ì›: ì˜ˆ")
    except ImportError:
        print("\nâŒ Transformers ë¯¸ì„¤ì¹˜")
        print("   ì„¤ì¹˜: pip install transformers")

def benchmark_image_processing():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("\nğŸ“¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    try:
        import cv2
        import numpy as np
        from PIL import Image
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        sizes = [(1920, 1080), (3840, 2160), (7680, 4320)]  # HD, 4K, 8K
        
        for width, height in sizes:
            print(f"\nì´ë¯¸ì§€ í¬ê¸°: {width}x{height}")
            
            # ëœë¤ ì´ë¯¸ì§€ ìƒì„±
            img_array = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
            
            # OpenCV ì²˜ë¦¬ ì‹œê°„
            start = time.time()
            gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            _, binary = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)
            cv_time = time.time() - start
            
            print(f"  â€¢ ì²˜ë¦¬ ì‹œê°„: {cv_time:.4f}ì´ˆ")
            print(f"  â€¢ ì²˜ë¦¬ ì†ë„: {width*height/cv_time/1e6:.1f} ë©”ê°€í”½ì…€/ì´ˆ")
            
    except ImportError:
        print("OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def optimize_tips():
    """ìµœì í™” íŒ"""
    print("\nğŸ’¡ GPU ìµœì í™” íŒ")
    print("="*60)
    
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        print(f"\ní˜„ì¬ GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
        
        if gpu_memory < 4:
            print("\nâš ï¸  ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
            print("  â€¢ ë°°ì¹˜ í¬ê¸°ë¥¼ 2-3ìœ¼ë¡œ ì„¤ì •")
            print("  â€¢ EasyOCR ì‚¬ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )")
            print("  â€¢ --workers 1 ì‚¬ìš©")
        elif gpu_memory < 8:
            print("\nâœ… ì ë‹¹í•œ ë©”ëª¨ë¦¬ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
            print("  â€¢ ë°°ì¹˜ í¬ê¸°ë¥¼ 5-8ë¡œ ì„¤ì •")
            print("  â€¢ PaddleOCR ë˜ëŠ” EasyOCR ì‚¬ìš©")
            print("  â€¢ --workers 2 ì‚¬ìš©")
        else:
            print("\nğŸ‰ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
            print("  â€¢ ë°°ì¹˜ í¬ê¸°ë¥¼ 10-20ìœ¼ë¡œ ì„¤ì •")
            print("  â€¢ PaddleOCR ì‚¬ìš© (ê°€ì¥ ë¹ ë¦„)")
            print("  â€¢ --workers 4 ì‚¬ìš©")
        
        print("\nì¶”ê°€ ìµœì í™”:")
        print("  â€¢ ê³ í•´ìƒë„ PDFëŠ” --dpi 150 ì‚¬ìš©")
        print("  â€¢ ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ --no-cache ì˜µì…˜ ê³ ë ¤")
        print("  â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì¬ì‹œì‘")

def main():
    print("="*60)
    print("ğŸ”¬ GPU í…ŒìŠ¤íŠ¸ ë° ìµœì í™” í™•ì¸")
    print("="*60)
    
    # GPU ì •ë³´
    if not print_gpu_info():
        print("\nğŸ’¡ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:")
        print("1. NVIDIA GPUê°€ í•„ìš”í•©ë‹ˆë‹¤")
        print("2. CUDA ë“œë¼ì´ë²„ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”")
        print("3. PyTorch GPU ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
        sys.exit(1)
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    try:
        test_gpu_performance()
    except Exception as e:
        print(f"\nâš ï¸  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # OCR ì—”ì§„ í™•ì¸
    test_ocr_engines()
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬
    benchmark_image_processing()
    
    # ìµœì í™” íŒ
    optimize_tips()
    
    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸš€ GPU ê°€ì† ì‹¤í–‰:")
    print("   python run_gpu.py documents/")
    print("\nğŸ“Š ì¼ë°˜ ì‹¤í–‰:")
    print("   python main.py documents/ --gpu --extract-all")
    print("="*60)

if __name__ == "__main__":
    main()